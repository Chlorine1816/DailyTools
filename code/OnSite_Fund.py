# -*- coding: utf-8 -*-  
import time,re,requests,os,json
import pandas as pd
from bs4 import BeautifulSoup
import numpy as np
from io import StringIO

headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36 Edg/88.0.705.74'}

corpid=os.environ['CORPID']  #å…¬å¸id
agentid=os.environ['AGENTID']  #æœºå™¨äººid
corpsecret=os.environ['CORPSECRET']  #æœºå™¨äººsecret
touser=os.environ['TOUSER']  #æ¥æ”¶id
media_id=os.environ['MEDIA'] #å›¾ç‰‡id

#å›¾æ–‡å›¾æ–‡æ¶ˆæ¯çš„æ ‡é¢˜
title=f'OnSite_Fund'
#å›¾æ–‡æ¶ˆæ¯çš„æè¿°ï¼Œä¸è¶…è¿‡512ä¸ªå­—èŠ‚
sio_digest=StringIO('')
sio_digest.write(time.strftime(f'%Y-%m-%d UTC(%H:%M)', time.localtime())+'\n')
#å›¾æ–‡æ¶ˆæ¯çš„å†…å®¹ï¼Œæ”¯æŒhtmlæ ‡ç­¾ï¼Œä¸è¶…è¿‡666 Kä¸ªå­—èŠ‚
sio_content=StringIO('')

def get_token():
    payload_access_token = {'corpid': corpid, 'corpsecret': corpsecret}
    token_url = 'https://qyapi.weixin.qq.com/cgi-bin/gettoken'
    r = requests.get(url=token_url, params=payload_access_token,headers=headers)
    dict_result = (r.json())
    return dict_result['access_token']

#å‘é€å›¾æ–‡ä¿¡æ¯
def send_mpnews(title,content,digest):
    time.sleep(2)
    access_token=get_token()
    url = f"https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token={access_token}"
    data = {
        "touser":touser, #æ¥æ”¶æ¶ˆæ¯äººå‘˜id
        "agentid": agentid, #æœºå™¨äººid
        'msgtype':'mpnews',
        'mpnews': {
            'articles':[
                {
                    "title": title, #å¿…é¡»
                    "thumb_media_id": media_id, #å¿…é¡»
                    "author": "Chlorine", #éå¿…é¡» ä½œè€…
                    "content": content, #å¿…é¡» ä¸è¶…è¿‡666 Kä¸ªå­—èŠ‚
                    "digest": digest #éå¿…é¡» ä¸è¶…è¿‡512ä¸ªå­—èŠ‚
                }
            ]
            },
        "safe": 0 #æ˜¯å¦åŠ å¯†
        }
    data = json.dumps(data, ensure_ascii=False)
    requests.post(url=url, data=data.encode("utf-8").decode("latin1"))

def get_daily_sentence():
    url = "http://open.iciba.com/dsapi/"
    r = requests.get(url)
    r = json.loads(r.text)
    content = r["content"]
    note = r["note"]
    sio_digest.write(f'{content}\n{note}\n')
    return None

def get_fund(code,per=10,sdate='',edate='',proxies=None):
    url='http://fund.eastmoney.com/f10/F10DataApi.aspx'
    params = {'type': 'lsjz', 'code': code, 'page':1,'per': per, 'sdate': sdate, 'edate': edate}
    req=requests.get(url=url,params=params,headers=headers)
    req.encoding='utf-8'   
    html=req.text
    bf=BeautifulSoup(html,'lxml')
    # è·å–æ€»é¡µæ•°
    pattern=re.compile(r'pages:(.*),')
    result=re.search(pattern,html).group(1)
    pages=int(result)
    # è·å–è¡¨å¤´
    heads = []
    for head in bf.find_all("th"):
        heads.append(head.contents[0])
    # æ•°æ®å­˜å–åˆ—è¡¨
    records = []
    # ä»ç¬¬1é¡µå¼€å§‹æŠ“å–æ‰€æœ‰é¡µé¢æ•°æ®
    page=1
    while page<=pages:
        time.sleep(0.2)
        params = {'type': 'lsjz', 'code': code, 'page':page,'per': per, 'sdate': sdate, 'edate': edate}
        req=requests.get(url=url,params=params,headers=headers,timeout=22)
        req.encoding='utf-8'   
        html=req.text
        bf=BeautifulSoup(html,'lxml')
        for row in bf.find_all("tbody")[0].find_all("tr"): 
            row_records = []
            for record in row.find_all('td'):
                val = record.contents
                # å¤„ç†ç©ºå€¼
                if val == []:
                    row_records.append(0)
                else:
                    row_records.append(val[0])
            records.append(row_records)
        page+=1
    data=pd.DataFrame()
    records=np.array(records)
    for col,col_name in enumerate(heads):
        data[col_name]=records[:,col]
    return data

def get_fund2(fund_id):
    url=f'http://fundf10.eastmoney.com/jjjz_{fund_id}.html'
    time.sleep(0.2)
    try:
        req=requests.get(url=url,headers=headers)
        req.encoding='utf-8'
        if req.status_code==200:
            html=req.text
    except:
        html=''
    bf=BeautifulSoup(html,'lxml')
    jz=bf.find_all('div',class_='bs_jz')
    jz=BeautifulSoup(str(jz),'lxml')
    #åç§°
    name=jz.find_all('h4',class_='title')[0].text
    return (name)

def writing1(name,jz,rq):
    sio_content.write(f'<div>{rq}</div>')
    sio_content.write(f'<div>{name}</div>')
    sio_content.write(f'<div><font color=\"comment\">å¯ä»¥æ“ä½œï¼</font></div>')
    up3,up2,up1,down1,down2,down3=updown(jz)
    sio_content.write(f'<div><font color=\"warning\">æ¶¨ 3% {up3}</font></div>')
    sio_content.write(f'<div><font color=\"warning\">æ¶¨ 2% {up2}</font></div>')
    sio_content.write(f'<div><font color=\"warning\">æ¶¨ 1% {up1}</font></div>')
    sio_content.write(f'<div><font color=\"info\">è·Œ 1% {down1}</font></div>')
    sio_content.write(f'<div><font color=\"info\">è·Œ 2% {down2}</font></div>')
    sio_content.write(f'<div><font color=\"info\">è·Œ 3% {down3}</font></div>')
    return None

def writing2(name,rq):
    sio_content.write(f'<div>{rq}</div>')
    sio_content.write(f'<div>{name}</div>')
    sio_content.write(f'<div><font color=\"comment\">åœæ­¢æ“ä½œï¼</font></div>')
    return None

def updown(jz):
    return(round(jz*1.03,3),round(jz*1.02,3),round(jz*1.01,3),round(jz*0.99,3),round(jz*0.98,3),round(jz*0.97,3))

def working(code):
    #è·å–å‡€å€¼ä¿¡æ¯
    edate=time.strftime("%Y-%m-%d", time.localtime(time.time()))
    sdate=time.strftime("%Y-%m-%d", time.localtime(time.time()-6666666))
    data=get_fund(code,per=22,sdate=sdate,edate=edate)
    data['å•ä½å‡€å€¼']=data['å•ä½å‡€å€¼'].astype(float)
    data['ç´¯è®¡å‡€å€¼']=data['ç´¯è®¡å‡€å€¼'].astype(float)
    data['æ—¥å¢é•¿ç‡']=data['æ—¥å¢é•¿ç‡'].str.strip('%').astype(float)
    # æŒ‰ç…§æ—¥æœŸå‡åºæ’åºå¹¶é‡å»ºç´¢å¼•
    data.drop(['ç”³è´­çŠ¶æ€','èµå›çŠ¶æ€','åˆ†çº¢é€é…'],axis=1,inplace=True)
    data=data.sort_values(by='å‡€å€¼æ—¥æœŸ',axis=0,ascending=True).reset_index(drop=True)
    name=get_fund2(code)
    jz_date=data['å‡€å€¼æ—¥æœŸ'].values[-1]
    lj_data=data['ç´¯è®¡å‡€å€¼'].values[-33:]
    jz_data=data['å•ä½å‡€å€¼'].values[-1]

    mean5=round(np.mean(lj_data[-5:]),3) #å‰5å¤©å‡€å€¼å‡å€¼
    mean10=round(np.mean(lj_data[-10:]),3)#å‰10å¤©å‡€å€¼å‡å€¼
    mean30=round(np.mean(lj_data[-30:]),3)#å‰30å¤©å‡€å€¼å‡å€¼

    if ((mean5 >= mean10)and(mean10 <= mean30))or((mean5 <= mean10)and(mean10 >= mean30))or(mean5 > mean10 > mean30):
        writing1(name,jz_data,jz_date)
    else:
        writing2(name,jz_date)

    '''
    if (mean5 > mean10 > mean30):
        news=f'<div><font color=\"warning\">å¤§å¹…ä¸Šæ¶¨</font></div>'
    elif (mean5 < mean10 < mean30):
        news=f'<div><font color=\"info\">å¤§å¹…ä¸‹è·Œ</font></div>'
    elif ((mean5 >= mean10)and(mean10 <= mean30))or((mean5 <= mean10)and(mean10 >= mean30)):
        news=f'<div><font color=\"warning\">ä¸Šæ¶¨</font></div>'
    elif ((mean5 <= mean10)and(mean10 >= mean30))or((mean5 >= mean10)and(mean10 <= mean30)):
        news=f'<div><font color=\"info\">ä¸‹è·Œ</font></div>'
    else:
        news=f'<div>æœªçŸ¥</div>'
    
    mean50=round(np.mean(lj_data),3) #å‰50å¤©å‡€å€¼å‡å€¼
    q1=round(np.quantile(lj_data,0.2),3) #å‰50å¤©å‡€å€¼ä¸‹äº”åˆ†ä½æ•°
    q4=round(np.quantile(lj_data,0.8),3) #å‰50å¤©å‡€å€¼ä¸Šäº”åˆ†ä½æ•°
    max_q=round(np.max(lj_data),3) #ä¸Šé™ #ä¸Šé™
    
    if (lj_data[-1] >= max_q):
        writing1('ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸš€',get_fund2(code),news,mean5,mean10,mean30,max_q,q4,mean50,q1)
        writing2(jz_date,lj_data[-1],jz_data,zf_data)
    elif (lj_data[-1] >= q4):
        writing1('ğŸ’—ğŸ’—ğŸ’—ğŸ’šğŸš€',get_fund2(code),news,mean5,mean10,mean30,max_q,q4,mean50,q1)
        writing2(jz_date,lj_data[-1],jz_data,zf_data)
    elif (lj_data[-1] >= mean50 ):
        writing1('ğŸ’—ğŸ’—ğŸ’šğŸ’šğŸš€',get_fund2(code),news,mean5,mean10,mean30,max_q,q4,mean50,q1)
        writing2(jz_date,lj_data[-1],jz_data,zf_data)
    elif (lj_data[-1] >= q1):
        writing1('ğŸ’—ğŸ’šğŸ’šğŸ’šğŸš€',get_fund2(code),news,mean5,mean10,mean30,max_q,q4,mean50,q1)
        writing2(jz_date,lj_data[-1],jz_data,zf_data)
    else:
        writing1('ğŸ’šğŸ’šğŸ’šğŸ’šğŸš€',get_fund2(code),news,mean5,mean10,mean30,max_q,q4,mean50,q1)
        writing2(jz_date,lj_data[-1],jz_data,zf_data)
    '''
    return None

if __name__=='__main__':
    start=time.perf_counter()
    fund_list=pd.read_excel('./data/OnSite_FundList.xlsx',dtype={'ID': 'string'})
    get_daily_sentence()
    for i in range(fund_list.shape[0]):
        time.sleep(0.2)
        code=fund_list['ID'].values[i]
        print(code)
        working(code)
    sio_digest.write(f'more ğŸ‘‰')
    sio_content.write(f'<div>â±</div>è¿è¡Œæ—¶é—´ï¼š{round((time.perf_counter()-start)/60,1)} åˆ†é’Ÿ')
    send_mpnews(title,sio_content.getvalue(),sio_digest.getvalue())